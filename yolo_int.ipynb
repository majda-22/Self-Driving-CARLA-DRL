{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import yolo\n",
    "# from IPython import display\n",
    "# display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "# yolo=YOLO(\"yolov8n.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "import carla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process(image):\n",
    "#     i=np.array(image.raw_data)\n",
    "#     i2=i.reshape((600,600,4))\n",
    "#     i3=i2[:,:,:3]\n",
    "#    # cv2.imshow(\"\",i3)\n",
    "#     # cv2.waitKey(1)\n",
    "#     normi=(i3/255.0)\n",
    "#     opi=cv2.cvtColor((normi*255).astype(np.uint8),cv2.COLOR_RGB2BGR)\n",
    "#     return opi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActorBlueprint(id=vehicle.tesla.model3,tags=[vehicle, tesla, model3])\n"
     ]
    }
   ],
   "source": [
    "#import random\n",
    "# client=carla.Client('localhost',2000)\n",
    "# client.set_timeout(2000.0)\n",
    "# world=client.get_world()\n",
    "# bpl=world.get_blueprint_library()\n",
    "# bp=bpl.filter('model3')[0]\n",
    "# print(bp)\n",
    "# spp=random.choice(world.get_map().get_spawn_points())\n",
    "# # sp=spp[0]\n",
    "# vl=world.spawn_actor(bp,spp)\n",
    "# actor_list.append(vl)\n",
    "# vp=vl.get_transform()\n",
    "\n",
    "client=carla.Client('localhost',2000)\n",
    "client.set_timeout(2000.0)\n",
    "world=client.get_world()\n",
    "bpl=world.get_blueprint_library()\n",
    "bp=bpl.filter('model3')[0]\n",
    "print(bp)\n",
    "spp=world.get_map().get_spawn_points()\n",
    "sp=spp[10]\n",
    "vl=world.spawn_actor(bp,sp)\n",
    "actor_list.append(vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#control the vehicle:\n",
    "def control_vehicle(traffic_light_state):\n",
    "    control = carla.VehicleControl()\n",
    "    if traffic_light_state == \"red\":\n",
    "        control.throttle = 0.0\n",
    "        control.brake = 1.0\n",
    "    elif traffic_light_state == \"green\":\n",
    "        control.throttle = 1.0\n",
    "        control.brake = 0.0\n",
    "    else:\n",
    "        # Default behavior if the traffic light state is not known\n",
    "        control.throttle = 0.5\n",
    "        control.brake = 0.0\n",
    "    vl.apply_control(control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO('yolov8n.pt')\n",
    "\n",
    "# Secondary model (yolotraficlight) for traffic light detection\n",
    "yolotraficlight = YOLO(\"C:/Users/ASUS/Downloads/CARLA_0.9.8/WindowsNoEditor/PythonAPI/examples/best1.pt\")\n",
    "\n",
    "import supervision as sv\n",
    "\n",
    "rf = Roboflow(api_key=\"PqaW7bzyyhdeZntUMVOJ\")\n",
    "project = rf.workspace().project(\"object-recognition-dddrb\")\n",
    "model = project.version(2).model\n",
    "\n",
    "def detect_traffic_light_state(image):\n",
    "    # Perform traffic light detection using yolotraficlight\n",
    "    result = yolotraficlight(image)[0]\n",
    "    print(\"bla bla bla bla bla bla\")\n",
    "    # Determine traffic light state (green, red, yellow)\n",
    "    for box in result.boxes:\n",
    "        state_label = result.names[int(box.cls[0])] \n",
    "        print(\"Detected traffic light state:\", state_label)\n",
    "        return state_label\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Callback function for processing each frame\n",
    "def cm_callback(image):\n",
    "    # Convert image to numpy array\n",
    "    img = np.array(image.raw_data).reshape((600, 600, 4))\n",
    "    img_color = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)  # Convert to BGR format\n",
    "    \n",
    "    # Perform object detection using YOLOv8 on color image\n",
    "    result = yolo(img_color)[0]\n",
    "\n",
    "    # Iterate over detected objects\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0]\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        \n",
    "        # Check if the detected object is a traffic light\n",
    "        label = result.names[int(box.cls[0])]\n",
    "        if label == \"traffic light\":\n",
    "            # Crop the region of interest containing the traffic light from the color image\n",
    "            traffic_light_roi = img_color\n",
    "\n",
    "            \n",
    "            # Detect traffic light state using yolotraficlight\n",
    "            traffic_light_state = detect_traffic_light_state(traffic_light_roi)\n",
    "            traffic_light_state = detect_traffic_light_state(traffic_light_roi)\n",
    "            control_vehicle(traffic_light_state)\n",
    "            \n",
    "            # Draw bounding box and label on the original image\n",
    "            cv2.rectangle(img_color, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(img_color, label + \": \" + traffic_light_state, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (36, 255, 12), 2)\n",
    "        else:\n",
    "            # Draw bounding box and label on the original image for non-traffic light objects\n",
    "            cv2.rectangle(img_color, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(img_color, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (36, 255, 12), 2)\n",
    "    \n",
    "    # Save or display the annotated image\n",
    "    frame_id = str(time.time())\n",
    "    file_path = os.path.join('data_carla', f'dete_obj_{frame_id}.png')\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    cv2.imwrite(file_path, img_color)\n",
    "    #cv2.imshow(\"Annotated Image\", img_color)\n",
    "    #cv2.waitKey(1)  # Use 1 ms waitKey to update the display window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vl.set_autopilot(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vehicle controle whitout autopilote\n",
    "#vl.apply_control(carla.VehicleControl(throttle=1.0,steer=0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp2=bpl.find('sensor.camera.rgb')\n",
    "bp2.set_attribute(\"image_size_x\",f'{600}')\n",
    "bp2.set_attribute(\"image_size_y\",f'{600}')\n",
    "bp2.set_attribute('fov','110')\n",
    "#position of the sensor\n",
    "ssp=carla.Transform(carla.Location(x=2.5,z=0.7))\n",
    "sn=world.spawn_actor(bp2,ssp,attach_to=vl)\n",
    "actor_list.append(sn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ultralytics YOLOv8.0.145  Python-3.7.0 torch-1.13.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "\n",
      "\n",
      "Ultralytics YOLOv8.0.145  Python-3.7.0 torch-1.13.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients\n",
      "Ultralytics YOLOv8.0.145  Python-3.7.0 torch-1.13.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients\n",
      "0: 640x640 (no detections), 5810.3ms\n",
      "Speed: 88.8ms preprocess, 5810.3ms inference, 70.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Ultralytics YOLOv8.0.145  Python-3.7.0 torch-1.13.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "0: 640x640 (no detections), 6318.1ms\n",
      "Speed: 57.2ms preprocess, 6318.1ms inference, 52.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5646.0ms\n",
      "Speed: 47.5ms preprocess, 5646.0ms inference, 63.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients\n",
      "0: 640x640 (no detections), 6139.0ms\n",
      "Speed: 35.3ms preprocess, 6139.0ms inference, 24.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6369.5ms\n",
      "Speed: 43.3ms preprocess, 6369.5ms inference, 44.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients\n",
      "0: 640x640 (no detections), 6440.3ms\n",
      "Speed: 111.4ms preprocess, 6440.3ms inference, 43.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6513.5ms\n",
      "Speed: 98.8ms preprocess, 6513.5ms inference, 307.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 8315.3ms\n",
      "Speed: 131.5ms preprocess, 8315.3ms inference, 258.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9424.1ms\n",
      "Speed: 63.4ms preprocess, 9424.1ms inference, 258.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9714.1ms\n",
      "Speed: 82.1ms preprocess, 9714.1ms inference, 130.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 9996.6ms\n",
      "Speed: 75.5ms preprocess, 9996.6ms inference, 111.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 11441.4ms\n",
      "Speed: 34.4ms preprocess, 11441.4ms inference, 38.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11427.3ms\n",
      "Speed: 22.4ms preprocess, 5713.6ms inference, 20.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 10462.4ms\n",
      "Speed: 213.6ms preprocess, 10462.4ms inference, 25.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 11189.3ms\n",
      "Speed: 173.4ms preprocess, 5594.6ms inference, 13.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 8433.6ms\n",
      "Speed: 208.5ms preprocess, 8433.6ms inference, 18.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 8482.8ms\n",
      "Speed: 327.4ms preprocess, 8482.8ms inference, 433.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 8843.5ms\n",
      "Speed: 93.6ms preprocess, 8843.5ms inference, 52.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 8187.5ms\n",
      "Speed: 55.6ms preprocess, 4093.7ms inference, 9.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 7364.1ms\n",
      "Speed: 103.7ms preprocess, 7364.1ms inference, 33.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 7493.9ms\n",
      "Speed: 30.7ms preprocess, 3746.9ms inference, 31.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 8306.6ms\n",
      "Speed: 180.2ms preprocess, 8306.6ms inference, 28.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 8044.4ms\n",
      "Speed: 23.8ms preprocess, 4022.2ms inference, 16.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 7415.1ms\n",
      "Speed: 424.9ms preprocess, 7415.1ms inference, 53.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 1 potted plant, 6517.6ms\n",
      "Speed: 174.3ms preprocess, 3258.8ms inference, 23.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 6306.4ms\n",
      "Speed: 49.2ms preprocess, 6306.4ms inference, 81.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6607.0ms\n",
      "Speed: 63.3ms preprocess, 6607.0ms inference, 385.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 5434.8ms\n",
      "Speed: 272.6ms preprocess, 2717.4ms inference, 20.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 5617.0ms\n",
      "Speed: 139.3ms preprocess, 1872.3ms inference, 37.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 5775.5ms\n",
      "Speed: 61.1ms preprocess, 5775.5ms inference, 24.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 1 traffic light, 5744.9ms\n",
      "Speed: 23.7ms preprocess, 2872.5ms inference, 20.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5355.4ms\n",
      "Speed: 73.5ms preprocess, 5355.4ms inference, 105.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 5651.4ms\n",
      "Speed: 37.1ms preprocess, 2825.7ms inference, 14.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 6571.5ms\n",
      "Speed: 91.5ms preprocess, 6571.5ms inference, 38.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 (no detections), 6478.6ms\n",
      "Speed: 101.9ms preprocess, 6478.6ms inference, 16.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6363.3ms\n",
      "Speed: 75.5ms preprocess, 6363.3ms inference, 24.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 5761.5ms\n",
      "Speed: 30.3ms preprocess, 2880.7ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 7202.2ms\n",
      "Speed: 195.2ms preprocess, 7202.2ms inference, 41.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "0: 640x640 1 airplane, 8046.8ms\n",
      "Speed: 116.8ms preprocess, 8046.8ms inference, 194.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 traffic lights, 9001.1ms\n",
      "Speed: 53.3ms preprocess, 9001.1ms inference, 108.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 traffic light, 9891.3ms\n",
      "Speed: 249.9ms preprocess, 4945.6ms inference, 34.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 traffic lights, 11011.8ms\n",
      "Speed: 10.2ms preprocess, 3670.6ms inference, 39.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 traffic lights, 10043.4ms\n",
      "Speed: 25.6ms preprocess, 2510.8ms inference, 29.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 traffic lights, 9077.4ms\n",
      "Speed: 26.3ms preprocess, 1815.5ms inference, 9.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 traffic lights, 8628.0ms\n",
      "Speed: 21.9ms preprocess, 1438.0ms inference, 37.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 3 traffic lights, 10078.0ms\n",
      "Speed: 19.0ms preprocess, 1439.7ms inference, 32.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "\n",
      "\n",
      "Ultralytics YOLOv8.0.145  Python-3.7.0 torch-1.13.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "Ultralytics YOLOv8.0.145  Python-3.7.0 torch-1.13.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "Ultralytics YOLOv8.0.145  Python-3.7.0 torch-1.13.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "Ultralytics YOLOv8.0.145  Python-3.7.0 torch-1.13.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "Ultralytics YOLOv8.0.145  Python-3.7.0 torch-1.13.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "Ultralytics YOLOv8.0.145  Python-3.7.0 torch-1.13.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "Ultralytics YOLOv8.0.145  Python-3.7.0 torch-1.13.1+cpu CPU (11th Gen Intel Core(TM) i7-1165G7 2.80GHz)\n",
      "0: 640x640 (no detections), 18466.1ms\n",
      "Speed: 151.6ms preprocess, 18466.1ms inference, 28.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 218 layers, 25841497 parameters, 0 gradients\n",
      "Model summary (fused): 218 layers, 25841497 parameters, 0 gradients\n",
      "Model summary (fused): 218 layers, 25841497 parameters, 0 gradients\n",
      "Model summary (fused): 218 layers, 25841497 parameters, 0 gradients\n",
      "Model summary (fused): 218 layers, 25841497 parameters, 0 gradients\n",
      "Model summary (fused): 218 layers, 25841497 parameters, 0 gradients\n",
      "Model summary (fused): 218 layers, 25841497 parameters, 0 gradients\n",
      "0: 640x640 (no detections), 19317.3ms\n",
      "Speed: 68.2ms preprocess, 19317.3ms inference, 50.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 2 traffic_light_reds, 19308.7ms\n",
      "Speed: 59.5ms preprocess, 9654.4ms inference, 21.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 traffic_light_reds, 23038.9ms\n",
      "Speed: 41.3ms preprocess, 23038.9ms inference, 173.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 24501.6ms\n",
      "Speed: 76.5ms preprocess, 24501.6ms inference, 76.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 traffic_light_reds, 24750.8ms\n",
      "Speed: 84.9ms preprocess, 24750.8ms inference, 180.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 3 traffic lights, 15109.7ms\n",
      "Speed: 256.9ms preprocess, 15109.7ms inference, 237.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 traffic_light_reds, 26134.7ms\n",
      "Speed: 134.5ms preprocess, 26134.7ms inference, 32.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 25792.0ms\n",
      "Speed: 254.9ms preprocess, 25792.0ms inference, 295.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 traffic_light_reds, 26252.1ms\n",
      "Speed: 205.9ms preprocess, 26252.1ms inference, 81.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 traffic_light_reds, 26744.9ms\n",
      "Speed: 179.3ms preprocess, 26744.9ms inference, 117.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 traffic lights, 15853.5ms\n",
      "Speed: 287.3ms preprocess, 15853.5ms inference, 153.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26649.8ms\n",
      "Speed: 61.3ms preprocess, 26649.8ms inference, 26.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 traffic_light_reds, 26426.6ms\n",
      "Speed: 257.5ms preprocess, 26426.6ms inference, 103.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 25841.5ms\n",
      "Speed: 135.0ms preprocess, 25841.5ms inference, 31.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 23374.3ms\n",
      "Speed: 270.5ms preprocess, 23374.3ms inference, 34.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 traffic_light_reds, 23685.5ms\n",
      "Speed: 345.3ms preprocess, 23685.5ms inference, 70.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_red\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 traffic_light_green, 1 traffic_light_red, 21895.2ms\n",
      "Speed: 127.7ms preprocess, 21895.2ms inference, 59.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 traffic lights, 14403.3ms\n",
      "Speed: 42.8ms preprocess, 7201.6ms inference, 98.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 20953.7ms\n",
      "Speed: 63.6ms preprocess, 20953.7ms inference, 23.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 traffic_light_green, 1 traffic_light_red, 19730.7ms\n",
      "Speed: 70.1ms preprocess, 19730.7ms inference, 103.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 3 traffic_light_greens, 20833.4ms\n",
      "Speed: 147.0ms preprocess, 20833.4ms inference, 112.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19429.9ms\n",
      "Speed: 105.2ms preprocess, 19429.9ms inference, 81.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n",
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 traffic_light_green, 2 traffic_light_reds, 20422.4ms\n",
      "Speed: 153.9ms preprocess, 20422.4ms inference, 96.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 traffic_light_green, 21106.7ms\n",
      "Speed: 75.5ms preprocess, 21106.7ms inference, 70.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 traffic_light_green, 1 traffic_light_red, 20743.5ms\n",
      "Speed: 116.4ms preprocess, 20743.5ms inference, 43.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 20630.7ms\n",
      "Speed: 62.2ms preprocess, 10315.3ms inference, 39.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 19400.0ms\n",
      "Speed: 75.4ms preprocess, 19400.0ms inference, 41.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 traffic_light_green, 1 traffic_light_red, 19242.0ms\n",
      "Speed: 131.2ms preprocess, 19242.0ms inference, 187.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 18982.5ms\n",
      "Speed: 107.8ms preprocess, 18982.5ms inference, 67.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 3 traffic_light_greens, 19254.0ms\n",
      "Speed: 148.4ms preprocess, 19254.0ms inference, 216.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 10950.6ms\n",
      "Speed: 127.2ms preprocess, 10950.6ms inference, 72.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 traffic_light_green, 2 traffic_light_reds, 19507.9ms\n",
      "Speed: 122.6ms preprocess, 19507.9ms inference, 63.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 1 traffic_light_green, 19349.9ms\n",
      "Speed: 101.6ms preprocess, 19349.9ms inference, 115.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 18182.7ms\n",
      "Speed: 143.4ms preprocess, 18182.7ms inference, 63.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 12093.5ms\n",
      "Speed: 137.5ms preprocess, 12093.5ms inference, 57.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 19936.2ms\n",
      "Speed: 83.2ms preprocess, 19936.2ms inference, 22.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 4 traffic_light_greens, 19054.9ms\n",
      "Speed: 118.0ms preprocess, 19054.9ms inference, 69.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 traffic_light_greens, 1 traffic_light_red, 19984.0ms\n",
      "Speed: 131.5ms preprocess, 19984.0ms inference, 49.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n",
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 19673.5ms\n",
      "Speed: 314.3ms preprocess, 19673.5ms inference, 56.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 traffic_light_greens, 1 traffic_light_red, 18725.6ms\n",
      "Speed: 112.6ms preprocess, 18725.6ms inference, 120.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 traffic_light_greens, 19276.9ms\n",
      "Speed: 106.1ms preprocess, 19276.9ms inference, 95.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    }
   ],
   "source": [
    "#vehicle controle without autopilote\n",
    "vl.apply_control(carla.VehicleControl(throttle=1.0,steer=0.0))\n",
    "sn.listen(cm_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 13553.8ms\n",
      "Speed: 105.1ms preprocess, 13553.8ms inference, 77.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 19861.8ms\n",
      "Speed: 165.3ms preprocess, 19861.8ms inference, 81.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 18932.6ms\n",
      "Speed: 77.7ms preprocess, 18932.6ms inference, 11.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 4 traffic_light_greens, 18668.5ms\n",
      "Speed: 37.3ms preprocess, 18668.5ms inference, 82.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 3 traffic_light_greens, 1 traffic_light_red, 18900.0ms\n",
      "Speed: 17.4ms preprocess, 9450.0ms inference, 38.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "0: 640x640 (no detections), 18664.9ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 34.7ms preprocess, 6221.6ms inference, 24.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 traffic_light_greens, 1 traffic_light_red, 17105.8ms\n",
      "Speed: 107.8ms preprocess, 17105.8ms inference, 21.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 traffic_light_greens, 16323.6ms\n",
      "Speed: 121.0ms preprocess, 8161.8ms inference, 31.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 13560.5ms\n",
      "Speed: 214.9ms preprocess, 13560.5ms inference, 19.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 9814.5ms\n",
      "Speed: 43.8ms preprocess, 4907.3ms inference, 14.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 10373.5ms\n",
      "Speed: 222.4ms preprocess, 10373.5ms inference, 14.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 traffic_light_greens, 8476.6ms\n",
      "Speed: 41.9ms preprocess, 4238.3ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 7717.1ms\n",
      "Speed: 33.1ms preprocess, 7717.1ms inference, 8.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 2 traffic_light_greens, 6928.9ms\n",
      "Speed: 107.6ms preprocess, 6928.9ms inference, 7.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n",
      "Detected traffic light state: traffic_light_green\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 5836.9ms\n",
      "Speed: 22.2ms preprocess, 2918.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 4011.1ms\n",
      "Speed: 30.5ms preprocess, 4011.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bla bla bla bla bla bla\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#vl.destroy()\n",
    "#sn.destroy()\n",
    "for actor in actor_list:\n",
    "     actor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
